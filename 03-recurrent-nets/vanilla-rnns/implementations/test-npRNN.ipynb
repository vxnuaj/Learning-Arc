{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "two layer RNN\n",
    "\n",
    "$h$ = hidden size for 1st layer.\n",
    "\n",
    "- Input $X_t \\in \\mathbb{R}^{n \\times d}$\n",
    "- First Layer Weights $W^{(1)} \\in \\mathbb{R}^{d \\times h}$ \n",
    "- First Layer Hidden State Weights $W_{h}^{(1)} \\in \\mathbb{R}^{h \\times h}$\n",
    "- First Layer Bias $b \\in \\mathbb{R}^{1 \\times h}$\n",
    "- First layer Output, $H_t^{(1)} \\in \\mathbb{R}^{n \\times h}$.\n",
    "- First Layer Hidden State, $H_{t-1}^{(1)} \\in \\mathbb{R}^{n \\times h}$\n",
    "\n",
    "```math\n",
    "\n",
    "H_t = \\phi(X_tW^{(1)} + H_{t-1}^{(1)}W_h^{(1)} + b)\n",
    "\n",
    "```\n",
    "\n",
    "$h_2$ = hidden size for 2nd layer.\n",
    "\n",
    "- Input $H_t^{(1)} \\in \\mathbb{R}^{n \\times h}$\n",
    "- Second Layer Weights $W^{(2)} \\in \\mathbb{R}^{h \\times h_2}$ \n",
    "- Second Layer Hidden State Weights $W_{h}^{(2)} \\in \\mathbb{R}^{h_2 \\times h_2}$\n",
    "- Second Layer Bias $b \\in \\mathbb{R}^{1 \\times h_2}$\n",
    "- Second layer Output, $H_t^{(2)} \\in \\mathbb{R}^{n \\times h_2}$.\n",
    "- Second Layer Hidden State, $H_{t-1}^{(1)} \\in \\mathbb{R}^{n \\times h_2}$\n",
    "\n",
    "second layer\n",
    "\n",
    "```math\n",
    "H_t^{(2)} = \\phi(H_t^{(1)}W^{(2)} + H_{t-1}^{(2)} W_h^{(2)} + b)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from npRNNv2 import RNN\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 20)\n",
      "[[array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])], [array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.]])]]\n"
     ]
    }
   ],
   "source": [
    "h_units = (10, 20)\n",
    "activation_funcs = ('tanh', 'tanh')\n",
    "in_dim = 50\n",
    "batch_size = 1\n",
    "\n",
    "rnn = RNN(h_units, activation_funcs, in_dim, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifying Internal Dims / Correct Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = rnn.weight\n",
    "h_weight = rnn.h_weight\n",
    "bias = rnn.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(weights))\n",
    "print(len(h_weight))\n",
    "print(len(bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$d = 50$<br/>\n",
    "$h = 10$<br/>\n",
    "$h_2 = 20$<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 Weights: (50, 10)\n",
      "Layer 1 Hidden State Weights: (10, 10)\n",
      "Layer 1 Bias: (1, 10)\n",
      "\n",
      "Layer 2 Weights: (10, 20)\n",
      "Layer 2 Hidden State Weights: (20, 20)\n",
      "Layer 2 Bias: (1, 20)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Layer 1 Weights: {weights[0].shape}\")\n",
    "print(f\"Layer 1 Hidden State Weights: {h_weight[0].shape}\")\n",
    "print(f\"Layer 1 Bias: {bias[0].shape}\")\n",
    "print()\n",
    "print(f\"Layer 2 Weights: {weights[1].shape}\")\n",
    "print(f\"Layer 2 Hidden State Weights: {h_weight[1].shape}\")\n",
    "print(f\"Layer 2 Bias: {bias[1].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch Size, $n = 1$<br/>\n",
    "Input, $X \\in \\mathbb{R}^{n \\times d} = \\mathbb{R}^{1 \\times 50}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialzing Random Data and Testing Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randn(1, 50)\n",
    "rnn._forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: (1, 50)\n",
      "Layer 1 Weight: (50, 10)\n",
      "Layer 1 Hidden Weight: (10, 10)\n",
      "Layer 1 Output: (1, 50, 10)\n",
      "\n",
      "Layer 2 Weight: (10, 20)\n",
      "Layer 2 Hidden Weight: (20, 20)\n",
      "Layer 2 Output: (1, 50, 20)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input: {X.shape}\") \n",
    "print(f\"Layer 1 Weight: {rnn.weight[0].shape}\") \n",
    "print(f\"Layer 1 Hidden Weight: {rnn.h_weight[0].shape}\")\n",
    "print(f\"Layer 1 Output: {rnn.a[0].shape}\")\n",
    "print(f\"\")\n",
    "print(f\"Layer 2 Weight: {rnn.weight[1].shape}\") \n",
    "print(f\"Layer 2 Hidden Weight: {rnn.h_weight[1].shape}\")\n",
    "print(f\"Layer 2 Output: {rnn.a[1].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now for multiple time steps,\n",
    "\n",
    "```math\n",
    "\\mathcal{X} = \\begin{bmatrix} X_1 & X_2 & \\dots & S \\end{bmatrix}\n",
    "\n",
    "\\\\[3mm]\n",
    "\n",
    "\\mathcal{X} = \\begin{bmatrix} \n",
    "\\begin{bmatrix} .2 & .3 & \\dots & d \\end{bmatrix} & \n",
    "\\begin{bmatrix} .5 & .2 & \\dots & d \\end{bmatrix} & \n",
    "\\cdots & \n",
    "\\begin{bmatrix} .9 & .1 & \\dots & d \\end{bmatrix}&\n",
    "S\n",
    "\\end{bmatrix} \\in \\mathbb{R}^{1 \\times d \\times S}\n",
    "\n",
    "```\n",
    "\n",
    "where $d$ is the dimensionality of the embedding space and $S$ is the fixed size sequence length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we'll be doing:\n",
    "\n",
    "$d = 50$ <br/>\n",
    "$S = 5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "[[array([[0., 0.]]), array([[0., 0.]])], [array([[0., 0., 0.]]), array([[0., 0., 0.]])]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "X = np.random.randn(1, 50, 5) # sequence length of 5 or time steps = 5\n",
    "\n",
    "h_units = (10, 20)\n",
    "activation_funcs = ('tanh', 'tanh')\n",
    "in_dim = 50\n",
    "seq_len = 2\n",
    "batch_size = 1\n",
    "\n",
    "rnn = RNN(h_units, activation_funcs, in_dim, seq_len, batch_size)\n",
    "rnn._forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [0. 0.]]\n",
      "[[ 1.86755799 -0.97727788]\n",
      " [ 0.95008842 -0.15135721]]\n",
      "[[ 0. -0.]\n",
      " [ 0. -0.]]\n"
     ]
    }
   ],
   "source": [
    "array = np.empty(shape = (2, 2))\n",
    "array_2 = np.random.randn(2, 2)\n",
    "\n",
    "print(array)\n",
    "print(array_2)\n",
    "\n",
    "print(array * array_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
